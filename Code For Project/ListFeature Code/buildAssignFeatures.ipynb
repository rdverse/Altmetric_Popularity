{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: David Gustafson\n",
    "ZID: z044140\n",
    "Class: CSCI 641, Fall 2018\n",
    "Description: \n",
    "1. create journal list\n",
    "2. assign journal prestige\n",
    "3. create publisher list\n",
    "4. assign publisher prestige\n",
    "5. create scopus list\n",
    "6. assign scopus prestige\n",
    "7. create author list\n",
    "8. assign author prestige\n",
    "9. Assign features to training/test set\n",
    "10. Create .csv file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create journal list: journal count, total journal altmetric score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building journal list...\n",
      "article count:  31\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "# Create journal list: journal count, total journal altmetric score\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_JSON = 'C:\\\\Users\\\\Dave\\\\Desktop\\\\bigData\\\\dump_sample_data_set\\\\List_Build_V1\\\\'\n",
    "\n",
    "\n",
    "\n",
    "subjectFlag = 0\n",
    "journalCount = 0\n",
    "add_count = 0\n",
    "article_count = 0\n",
    "\n",
    "temp_alt = 0\n",
    "stored_alt = 0\n",
    "\n",
    "temp_loc = 0\n",
    "last_row = 0\n",
    "\n",
    "journal_array = []\n",
    "key = ''\n",
    "a = {}\n",
    "df_count = 0\n",
    "\n",
    "\n",
    "\n",
    "# output\n",
    "print('building journal list...')\n",
    "\n",
    "\n",
    "# loop through files in folder\n",
    "for filename in os.listdir(PATH_TO_JSON):\n",
    "    \n",
    "    \n",
    "    # open folder\n",
    "    for folder in os.listdir(PATH_TO_JSON + filename):\n",
    "    \n",
    "    \n",
    "         # open file\n",
    "        with open(PATH_TO_JSON + filename + '\\\\' + folder) as source_file:\n",
    "    \n",
    "            # count the articles\n",
    "            article_count += 1\n",
    "\n",
    "            # assign the json file's data to an object\n",
    "            json_data = json.load(source_file)\n",
    "\n",
    "            # loop through the citation object\n",
    "            for object_type in json_data['citation']:\n",
    "\n",
    "                # look for the subject(s)\n",
    "                if(object_type == 'journal'):\n",
    "\n",
    "                    # loop through the subject array\n",
    "                    for journal_index in json_data['citation']['journal']:\n",
    "\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        \n",
    "                        # ADD COUNT TO AN EXISTING JOURNAL\n",
    "                        authorFlag2 = 0\n",
    "\n",
    "                        this_index = 0\n",
    "                        while this_index < journalCount:\n",
    "\n",
    "                            for key in journal_array[this_index]:\n",
    "\n",
    "                                # check if there is a journal\n",
    "                                if(key == json_data['citation']['journal']):\n",
    "                                    \n",
    "                                    # add 1 to the count of the journal\n",
    "                                    journal_array[this_index][key][0] += 1\n",
    "                                    \n",
    "                                    # count that count\n",
    "                                    add_count += 1\n",
    "\n",
    "                                    # this is only for visually updating output\n",
    "                                    df_count += 1\n",
    "\n",
    "                                    # get new altmetric score for new jouranl\n",
    "                                    temp_alt = json_data['altmetric_score']['score']\n",
    "\n",
    "                                    # add 1 to the count\n",
    "                                    journal_array[this_index][key][1] += temp_alt\n",
    "                                    \n",
    "\n",
    "                                    # set subjectFlag to 1\n",
    "                                    subjectFlag = 1\n",
    "\n",
    "                                    break\n",
    "\n",
    "                            # add 1 to the index\n",
    "                            this_index += 1\n",
    "                            \n",
    "                            \n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                                \n",
    "                                \n",
    "                        # ADD A NEW JOURNAL TO THE LIST \n",
    "                        if(subjectFlag == 0):\n",
    "\n",
    "                            # add_count is for updating the output\n",
    "                            journalCount += 1\n",
    "\n",
    "                            key = json_data['citation']['journal'] \n",
    "                            \n",
    "                            # get new altmetric score for new jouranl\n",
    "                            temp_alt = json_data['altmetric_score']['score']\n",
    "                            \n",
    "                            #a.setdefault( key, [ count_value, altmetric_score, prestige_score ])\n",
    "                            a.setdefault( key, [1, temp_alt, 0])\n",
    "                        \n",
    "                            # add the dictionary to the next spot in the array\n",
    "                            journal_array.append(a)\n",
    "                        \n",
    "                            # clear the temporary arrays, dictionaries\n",
    "                            a = {}\n",
    "                            \n",
    "\n",
    "                        # assign subjectFlag the value of 0\n",
    "                        subjectFlag = 0\n",
    "                        \n",
    "                        break\n",
    "                        \n",
    "            \n",
    "            # this is only for visually updating output\n",
    "            if( article_count % 10000 == 0):\n",
    "                print('article_count: ', article_count)\n",
    " \n",
    "\n",
    "            # close the current source file\n",
    "            source_file.close()\n",
    "\n",
    "print('article count: ', article_count)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get journal prestige score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "# get journal prestige score\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "temp_altcount = 0\n",
    "temp_prestige = 0\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "    \n",
    "# loop through the journal_array to check if the journal is inside the array \n",
    "that_index = 0\n",
    "while that_index < len(journal_array):\n",
    "\n",
    "    for key in journal_array[that_index]:\n",
    "        \n",
    "        # calculate prestige\n",
    "        temp_prestige = journal_array[that_index][key][1] / journal_array[that_index][key][0]\n",
    "        journal_array[that_index][key][2] = temp_prestige\n",
    "        \n",
    "        \n",
    "    that_index += 1\n",
    "    \n",
    "\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create publisher list: publisher count, total publisher altmetric score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building publisher list...\n",
      "popularAltmetricScores\n",
      "article count:  31\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "# Create publisher list: publisher count, total publisher altmetric score\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_JSON = 'C:\\\\Users\\\\Dave\\\\Desktop\\\\bigData\\\\dump_sample_data_set\\\\List_Build_V1\\\\'\n",
    "\n",
    "\n",
    "subjectFlag = 0\n",
    "publisherCount = 0\n",
    "add_count = 0\n",
    "article_count = 0\n",
    "\n",
    "temp_alt = 0\n",
    "stored_alt = 0\n",
    "\n",
    "temp_loc = 0\n",
    "last_row = 0\n",
    "\n",
    "publisher_array = []\n",
    "key = ''\n",
    "a = {}\n",
    "df_count = 0\n",
    "\n",
    "\n",
    "# output\n",
    "print('building publisher list...')\n",
    "\n",
    "\n",
    "# loop through files in folder\n",
    "for filename in os.listdir(PATH_TO_JSON):\n",
    "    \n",
    "    print(filename)\n",
    "    # open folder\n",
    "    for folder in os.listdir(PATH_TO_JSON + filename):\n",
    "        \n",
    "        \n",
    "         # open file\n",
    "        with open(PATH_TO_JSON + filename + '\\\\' + folder) as source_file:\n",
    "    \n",
    "            # count the articles\n",
    "            article_count += 1\n",
    "\n",
    "            # assign the json file's data to an object\n",
    "            json_data = json.load(source_file)\n",
    "\n",
    "            # loop through the citation object\n",
    "            for object_type in json_data['citation']:\n",
    "\n",
    "                # look for the subject(s)\n",
    "                if(object_type == 'publisher'):\n",
    "\n",
    "                    # loop through the subject array\n",
    "                    for publisher_index in json_data['citation']['publisher']:\n",
    "\n",
    "\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        \n",
    "                        # ADD COUNT TO AN EXISTING publisher\n",
    "                        authorFlag2 = 0\n",
    "\n",
    "                        this_index = 0\n",
    "                        while this_index < publisherCount:\n",
    "                            \n",
    "                            for key in publisher_array[this_index]:\n",
    "\n",
    "                                if(key == json_data['citation']['publisher']):\n",
    "                                    \n",
    "                                    # add 1 to the count of this publisher\n",
    "                                    publisher_array[this_index][key][0] += 1\n",
    "                                    \n",
    "                                    # count that count\n",
    "                                    add_count += 1\n",
    "\n",
    "                                    # this is only for visually updating output\n",
    "                                    df_count += 1\n",
    "\n",
    "                                    # get new altmetric score for new jouranl\n",
    "                                    temp_alt = json_data['altmetric_score']['score']\n",
    "\n",
    "                                    publisher_array[this_index][key][1] += temp_alt\n",
    "\n",
    "                                    # set subjectFlag to 1\n",
    "                                    subjectFlag = 1\n",
    "\n",
    "                                    break\n",
    "                                    \n",
    "                            this_index += 1\n",
    "                            \n",
    "                            \n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                                \n",
    "                        # ADD A NEW publisher TO THE LIST \n",
    "                        if(subjectFlag == 0):\n",
    " \n",
    "                            publisherCount += 1\n",
    "\n",
    "                            key = json_data['citation']['publisher'] \n",
    "                            \n",
    "                            # get new altmetric score for new jouranl\n",
    "                            temp_alt = json_data['altmetric_score']['score']\n",
    "                            \n",
    "                            #a.setdefault( key, [ count_value, altmetric_score, prestige_score ])\n",
    "                            a.setdefault( key, [1, temp_alt, 0])\n",
    "                        \n",
    "                            # add the dictionary to the next spot in the array\n",
    "                            publisher_array.append(a)\n",
    "                        \n",
    "                            # clear the temporary arrays, dictionaries\n",
    "                            a = {}\n",
    "                            \n",
    "                        # assign subjectFlag the value of 0\n",
    "                        subjectFlag = 0\n",
    "                        \n",
    "                        break\n",
    "                        \n",
    "            # this is only for visually updating output\n",
    "            if( article_count % 10000 == 0):\n",
    "                print('article_count: ', article_count)\n",
    "\n",
    "\n",
    "            # close the current source file\n",
    "            source_file.close()\n",
    "        \n",
    "\n",
    "print('article count: ', article_count)\n",
    "print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Publisher Prestige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 4\n",
    "# Calculate Publisher Prestige\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "temp_altcount = 0\n",
    "temp_prestige = 0\n",
    "\n",
    "#print('\\n')\n",
    "\n",
    "# loop through the journal_array to check if the journal is inside the array \n",
    "that_index = 0\n",
    "while that_index < len(publisher_array):\n",
    "    \n",
    "    for key in publisher_array[that_index]:\n",
    "        \n",
    "        # calculate prestige\n",
    "        temp_prestige = publisher_array[that_index][key][1] / publisher_array[that_index][key][0]\n",
    "        publisher_array[that_index][key][2] = temp_prestige\n",
    "        \n",
    "        \n",
    "    that_index += 1\n",
    "    \n",
    "\n",
    "    \n",
    "print('\\n')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create scopus list: scopus count, total scopus altmetric score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building scopus list...\n",
      "popularAltmetricScores\n",
      "total article count:  31\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "# Create scopus list: scopus count, total scopus altmetric score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_JSON = 'C:\\\\Users\\\\Dave\\\\Desktop\\\\bigData\\\\dump_sample_data_set\\\\List_Build_V1\\\\'\n",
    "\n",
    "\n",
    "\n",
    "subjectFlag = 0\n",
    "scopusCount = 0\n",
    "add_count = 0\n",
    "article_count = 0\n",
    "\n",
    "temp_alt = 0\n",
    "stored_alt = 0\n",
    "\n",
    "temp_loc = 0\n",
    "last_row = 0\n",
    "\n",
    "scopus_array = []\n",
    "s_key = ''\n",
    "a = {}\n",
    "df_count = 0\n",
    "\n",
    "\n",
    "print('building scopus list...')\n",
    "\n",
    "\n",
    "# loop through files in folder\n",
    "for filename in os.listdir(PATH_TO_JSON):\n",
    "    \n",
    "    \n",
    "    print(filename)\n",
    "    # open folder\n",
    "    for folder in os.listdir(PATH_TO_JSON + filename):\n",
    "    \n",
    "    \n",
    "         # open file\n",
    "        with open(PATH_TO_JSON + filename + '\\\\' + folder) as source_file:\n",
    "    \n",
    "            # count the articles\n",
    "            article_count += 1\n",
    "\n",
    "            # assign the json file's data to an object\n",
    "            json_data = json.load(source_file)\n",
    "\n",
    "\n",
    "            # loop through the citation object\n",
    "            for object_type in json_data['citation']:\n",
    "\n",
    "\n",
    "\n",
    "                # look for the subject(s)\n",
    "                if(object_type == 'scopus_subjects'):\n",
    "\n",
    "\n",
    "                    # loop through the subject array\n",
    "                    for scopus_index in json_data['citation']['scopus_subjects']:\n",
    "\n",
    "   \n",
    "\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                        \n",
    "\n",
    "                        # ADD COUNT TO AN EXISTING scopus\n",
    "                        authorFlag2 = 0\n",
    "    \n",
    "                        this_index = 0\n",
    "                        while this_index < scopusCount:\n",
    "                        \n",
    "                            for key in scopus_array[this_index]:\n",
    "\n",
    "\n",
    "                                if(key == json_data['citation']['scopus_subjects'][0]):\n",
    "                                    \n",
    "                                    \n",
    "                                    # add 1 to the count of this scopus\n",
    "                                    scopus_array[this_index][key][0] += 1\n",
    "                                    \n",
    "\n",
    "                                    # this is only for visually updating output\n",
    "                                    df_count += 1\n",
    "\n",
    "                                    \n",
    "                                    # get new altmetric score for new jouranl\n",
    "                                    temp_alt = json_data['altmetric_score']['score']\n",
    "\n",
    "\n",
    "                                    scopus_array[this_index][key][1] += temp_alt\n",
    "\n",
    "                                    # add_count\n",
    "                                    add_count += 1\n",
    "\n",
    "\n",
    "                                    # set subjectFlag to 1 so that you do not add a new scopus\n",
    "                                    subjectFlag = 1\n",
    "\n",
    "                                    break\n",
    "                                    \n",
    "                                    \n",
    "                            # updata this index\n",
    "                            this_index += 1\n",
    "                            \n",
    "                            \n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                        # ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL ADD JOURNAL\n",
    "                                \n",
    "\n",
    "                        if(subjectFlag == 0):\n",
    "                            \n",
    "                            # add_count is for updating the output\n",
    "                            scopusCount += 1\n",
    "                           \n",
    "                            \n",
    "                            # assign the scopus subjects array to a variable\n",
    "                            s_key = json_data['citation']['scopus_subjects'] \n",
    "                            \n",
    "                            \n",
    "                            # get new altmetric score for new jouranl\n",
    "                            temp_alt = json_data['altmetric_score']['score']\n",
    "                            \n",
    "                            #a.setdefault( key, [ count_value, altmetric_score, prestige_score ])\n",
    "                            a.setdefault( s_key[0], [1, temp_alt, 0])\n",
    "                        \n",
    "                            # add the dictionary to the next spot in the array\n",
    "                            scopus_array.append(a)\n",
    "                        \n",
    "                        \n",
    "                            # clear the temporary arrays, dictionaries\n",
    "                            a = {}\n",
    "\n",
    "                        \n",
    "                        # assign subjectFlag the value of 0\n",
    "                        subjectFlag = 0\n",
    "                        \n",
    "                        break\n",
    "\n",
    "      \n",
    "            \n",
    "            # update output\n",
    "            if( article_count % 10000 == 0):\n",
    "                print('article_count: ', article_count)\n",
    "\n",
    "\n",
    "            # close the current source file\n",
    "            source_file.close()\n",
    "        \n",
    "        \n",
    "\n",
    "print('total article count: ', article_count)\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Get scopus prestige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "# Get scopus prestige\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "temp_altcount = 0\n",
    "temp_prestige = 0\n",
    "\n",
    "\n",
    "    \n",
    "# loop through the journal_array to check if the journal is inside the array \n",
    "that_index = 0\n",
    "\n",
    "while that_index < len(scopus_array):\n",
    "    \n",
    "    for key in scopus_array[that_index]:\n",
    "        \n",
    "        # calculate prestige\n",
    "        temp_prestige = scopus_array[that_index][key][1] / scopus_array[that_index][key][0]\n",
    "        scopus_array[that_index][key][2] = temp_prestige\n",
    "        \n",
    "        \n",
    "    that_index += 1\n",
    "    \n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Build author list, get count, get total altmetric score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building author list...\n",
      "article_count:  31\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "# build author list, get count, get total altmetric score\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_JSON = 'C:\\\\Users\\\\Dave\\\\Desktop\\\\bigData\\\\dump_sample_data_set\\\\List_Build_V1\\\\'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "authorFlag = 0\n",
    "\n",
    "noAuthorFlag = 0\n",
    "noAuthor_array = []\n",
    "previous_source = ''\n",
    "\n",
    "author_array=[]\n",
    "\n",
    "\n",
    "# array to hold the author names from the json data\n",
    "json_array = []\n",
    "\n",
    "# array to hold the tokenized author names from the json_array\n",
    "temp_array = []\n",
    "temp_name = ''\n",
    "token = []\n",
    "df_array = []\n",
    "new_name = ''\n",
    "holder_array = []\n",
    "\n",
    "article_count = 0\n",
    "\n",
    "\n",
    "collected = 0\n",
    "not_collected = 0\n",
    "\n",
    "\n",
    "#json_hold_data = []\n",
    "holder = ''\n",
    "\n",
    "\n",
    "\n",
    "# step 2 variables\n",
    "author_array = []\n",
    "df_count = 0\n",
    "\n",
    "author_array_count = 0\n",
    "array_count = 0\n",
    "array2_count = 0\n",
    "authorFlag2 = 0\n",
    "\n",
    "temp_alt = 0\n",
    "a = {}\n",
    "# end step 2 variables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('building author list...')\n",
    "\n",
    "# loop through files in folder\n",
    "for filename in os.listdir(PATH_TO_JSON):\n",
    "    \n",
    "    \n",
    "    # open folder\n",
    "    for folder in os.listdir(PATH_TO_JSON + filename):\n",
    "    \n",
    "    \n",
    "        # open file\n",
    "        with open(PATH_TO_JSON + filename + '\\\\' + folder) as source_file:\n",
    "            \n",
    "            \n",
    "            # assign the json file's data to an object\n",
    "            json_data = json.load(source_file)\n",
    "\n",
    "\n",
    "            article_count += 1\n",
    "\n",
    "            \n",
    "            # loop through the citation object\n",
    "            for object_type in json_data['citation']:\n",
    "\n",
    "\n",
    "                # look for the subject(s)\n",
    "                if(object_type == 'authors'):\n",
    "\n",
    "\n",
    "                    # loop through the author array in json file and put every author into the json_array\n",
    "                    for author_index in json_data['citation']['authors']:\n",
    "                        \n",
    "                        # check for null, if its null (None) continue to the next file\n",
    "                        if(author_index == None):\n",
    "                            \n",
    "                            continue\n",
    "                        \n",
    "                        # check for an array (list), if its an array skip it\n",
    "                        if(author_index == []):\n",
    "                            \n",
    "\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "                        # parse through the author here and normalize it\n",
    "                        name = author_index\n",
    "\n",
    "                        # tokenize the token array\n",
    "                        json_array.append(word_tokenize(name))   \n",
    "\n",
    "\n",
    "                    # loop through the token and take out token with a comma, and tokens that have 2 or less characters\n",
    "                    for i in json_array:\n",
    "                        \n",
    "                        # loop through the elements in token array\n",
    "                        for j in i:\n",
    "\n",
    "                            # COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA\n",
    "                            # COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA\n",
    "                            # COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA\n",
    "                            # COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA COMMA\n",
    "                            if j == ',':\n",
    "\n",
    "                                # temp_array is an array of tokenized authors, there should ever by 1 author in it\n",
    "                                temp_array.append(i)\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                # temp_i is a token from the 1 author in the temp_array, so this will loop through multiple tokens\n",
    "                                for temp_i in temp_array:\n",
    "                                \n",
    "                                    # if there are 3 tokens\n",
    "                                    if(len(temp_i) == 3 ):\n",
    "\n",
    "                                        # hold the lastName\n",
    "                                        temp_name = temp_i[0]\n",
    "\n",
    "                                        # put the firstName in the first element\n",
    "                                        holder_array.append(temp_i[2])\n",
    "\n",
    "                                        # put the lastName in the second element\n",
    "                                        holder_array.append(temp_name)\n",
    "\n",
    "\n",
    "                                        token.append(holder_array)\n",
    "                                        \n",
    "                                        # clear the arrays for next author\n",
    "                                        holder_array = []\n",
    "                                        json_array = []\n",
    "                                        \n",
    "                                        authorFlag = 1\n",
    "                                        break\n",
    "                                        \n",
    "        \n",
    "                                # clear the temp_array\n",
    "                                temp_array = []\n",
    "        \n",
    "                            \n",
    "                                break\n",
    "                    \n",
    "\n",
    "                            # INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS\n",
    "                            # INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS\n",
    "                            # INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS\n",
    "                            # INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS INITIALS\n",
    "                            \n",
    "                            if len(j) <= 2:\n",
    "                                # if a string in the author name has a length of 2 or less we don't want it\n",
    "                                \n",
    "                                break\n",
    "                            \n",
    "\n",
    "                            # if the element in i is equal to the last element in the author name\n",
    "                            if(i.index(j) == len(i) - 1):\n",
    "\n",
    "                                #keep the rest\n",
    "                                token.append(i)\n",
    "                            \n",
    "                                # clear the json_array \n",
    "                                json_array = []\n",
    "                                \n",
    "                                # assign subjectFlag the value of 0\n",
    "                                authorFlag = 1\n",
    "                                \n",
    "                                break\n",
    "                    \n",
    "\n",
    "                        if(authorFlag == 1):\n",
    "                            \n",
    "                            \n",
    "                            # authors that were collected\n",
    "                            collected += 1\n",
    "                            \n",
    "\n",
    "                            # reset the authorFlag first\n",
    "                            authorFlag = 0\n",
    "                            break\n",
    "                        \n",
    "                        #if the current token is the last in an author's name\n",
    "                        if(json_array.index(i) == len(json_array) - 1): \n",
    "\n",
    "                            not_collected += 1\n",
    "\n",
    "                            noAuthor_array.append(source_file)\n",
    "                         \n",
    "\n",
    "            if(token != []):\n",
    "            \n",
    "                df_array = []\n",
    "                holder = ''\n",
    "\n",
    "                # CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY\n",
    "                # CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY\n",
    "                # CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY\n",
    "                # CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY CONCATENATE ARRAY\n",
    "\n",
    "                # loop through the token array and concatenatate the words with a space\n",
    "                for i in token:\n",
    "\n",
    "                    for j in i:\n",
    "\n",
    "                        new_name += j\n",
    "                        new_name += ' '\n",
    "\n",
    "                    # add the new_name to the end of the array\n",
    "                    #df_array.append(new_name)\n",
    "                    holder = new_name\n",
    "                    \n",
    "                    # clear the new_name to start over\n",
    "                    new_name = ''\n",
    "\n",
    "               \n",
    "                #print('done concatenating')\n",
    "\n",
    "                # clear out the token\n",
    "                token = []\n",
    "\n",
    "                checkFlag = 0\n",
    "                \n",
    "\n",
    "                # reset author flag to 0, it will only change back to 1 if the current author in author_index goes up 1\n",
    "                authorFlag2 = 0\n",
    "\n",
    "\n",
    "                # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "                # ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT ADD COUNT\n",
    "\n",
    "                # ADD COUNT TO AN EXISTING author\n",
    "                # for all authors\n",
    "                this_index = 0\n",
    "                while this_index < author_array_count:\n",
    "                    \n",
    "                    # for the key in the author array at this index\n",
    "                    for key in author_array[this_index]:\n",
    "\n",
    "\n",
    "                        # check if the author is the current author\n",
    "                        if(key == holder):\n",
    "\n",
    "                            # add 1 to the count of the author \n",
    "                            author_array[this_index][key][0] += 1\n",
    "\n",
    "\n",
    "                            # get new altmetric score for new author\n",
    "                            temp_alt = json_data['altmetric_score']['score']\n",
    "\n",
    "\n",
    "\n",
    "                            # add the altmetric score of this article to the running total in this author\n",
    "                            author_array[this_index][key][1] += temp_alt\n",
    "\n",
    "\n",
    "                            # this is only for visually updating output\n",
    "                            df_count += 1\n",
    "                            \n",
    "                            authorFlag2 = 1\n",
    "                            checkFlag = 1\n",
    "                            break\n",
    "\n",
    "                    # go to the next index in the author_array\n",
    "                    this_index += 1\n",
    "                    if(checkFlag == 1):\n",
    "                        break\n",
    "\n",
    "\n",
    "                # ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR\n",
    "                # ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR\n",
    "                # ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR\n",
    "                # ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR\n",
    "                # ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR\n",
    "                # ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR ADD AUTHOR\n",
    "\n",
    "\n",
    "                #else add the new subject with a count of 1, once it goes through the entire array\n",
    "                if(authorFlag2 == 0):\n",
    "\n",
    "                    # get new altmetric score for new jouranl\n",
    "                    temp_alt = json_data['altmetric_score']['score']\n",
    "\n",
    "                    # create a dictionary with a key and array to hold multiple values\n",
    "                    a.setdefault( holder, [1, temp_alt, 0])\n",
    "\n",
    "                    # add the dictionary to the next spot in the array\n",
    "                    author_array.append(a)\n",
    "\n",
    "                    # clear the dictionary after you use it or you will keep adding to old values\n",
    "                    a = {}\n",
    "                    \n",
    "                    # when you add an author to the array add 1 to the count\n",
    "                    author_array_count += 1\n",
    "                    \n",
    "  \n",
    "            # this is only for visually updating output\n",
    "            if( article_count % 10000 == 0):\n",
    "                print('article_count: ', article_count)\n",
    "\n",
    "\n",
    "            # close the current source file\n",
    "            source_file.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('article_count: ', article_count)\n",
    "print('done')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Get author prestige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "# Get author prestige\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "temp_altcount = 0\n",
    "temp_prestige = 0\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "    \n",
    "# loop through the author_array\n",
    "that_index = 0\n",
    "while that_index < len(author_array):\n",
    "    \n",
    "    # for the key in the author array at this index\n",
    "    for key in author_array[that_index]:\n",
    "        \n",
    "        temp_prestige = author_array[that_index][key][1] / author_array[that_index][key][0]\n",
    "        author_array[that_index][key][2] = temp_prestige\n",
    "        \n",
    "        \n",
    "    that_index += 1\n",
    "    \n",
    "\n",
    "    \n",
    "print('\\n')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Assign features to train/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID working...\n",
      "article count is:  31\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "# Assign features to train/test set\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "PATH_TO_JSON = 'C:\\\\Users\\\\Dave\\\\Desktop\\\\bigData\\\\dump_sample_data_set\\\\Clean_Balanced_V3\\\\'\n",
    "\n",
    "\n",
    "\n",
    "article_count = 0\n",
    "id_count = 0\n",
    "add_count = 0\n",
    "df_count = 0\n",
    "\n",
    "\n",
    "\n",
    "temp_alt = 0\n",
    "stored_alt = 0\n",
    "\n",
    "\n",
    "\n",
    "id_array = []\n",
    "a = {}\n",
    "\n",
    "\n",
    "id_key = 0\n",
    "journal_name = ''\n",
    "publisher_name = ''\n",
    "scopus_name = ''\n",
    "author_name = ''\n",
    "\n",
    "\n",
    "# features\n",
    "altmetric_score = 0\n",
    "\n",
    "journal_count = 0\n",
    "journal_prestige = 0\n",
    "publisher_count = 0\n",
    "publisher_prestige = 0\n",
    "scopus_count = 0\n",
    "scopus_prestige = 0\n",
    "author_count = 0\n",
    "author_prestige = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for get author\n",
    "name = ''\n",
    "json_array = []\n",
    "temp_array = []\n",
    "holder_array = []\n",
    "author_get_count = 0\n",
    "holder = ''\n",
    "new_name = ''\n",
    "collected = 0\n",
    "not_collected = 0\n",
    "\n",
    "\n",
    "# target class\n",
    "popular_class = ''\n",
    "\n",
    "\n",
    "# for checking\n",
    "source = ''\n",
    "\n",
    "\n",
    "print('ID working...')\n",
    "\n",
    "\n",
    "# loop through files in folder\n",
    "for filename in os.listdir(PATH_TO_JSON):\n",
    "    \n",
    "    \n",
    "    # open folder\n",
    "    for folder in os.listdir(PATH_TO_JSON + filename):\n",
    "    \n",
    "    \n",
    "         # open file\n",
    "        with open(PATH_TO_JSON + filename + '\\\\' + folder) as source_file:\n",
    "    \n",
    "            source = source_file\n",
    "    \n",
    "            # count the articles\n",
    "            article_count += 1\n",
    "\n",
    "            # assign the json file's data to an object\n",
    "            json_data = json.load(source_file)\n",
    "\n",
    "\n",
    "            \n",
    "            # get the altmetric_score\n",
    "            # re-initalize before\n",
    "            altmetric_score = 0\n",
    "            altmetric_score = json_data['altmetric_score']['score']\n",
    "            \n",
    "            \n",
    "            # get the altmetric_id\n",
    "            temp_alt = json_data['altmetric_id']\n",
    "            temp_alt = str(temp_alt)\n",
    "            \n",
    "            \n",
    "            # GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES\n",
    "            # GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES\n",
    "            # GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES\n",
    "            # GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES\n",
    "            # GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES GET THE ATTRIBUTES\n",
    "            \n",
    "            # loop through the citation object\n",
    "            for object_type in json_data['citation']:\n",
    "\n",
    "                # get the journal_name\n",
    "                # look for the JOURNAL\n",
    "                if(object_type == 'journal'):\n",
    "                    \n",
    "                    journal_name = json_data['citation']['journal']\n",
    "                    \n",
    "                    \n",
    "   \n",
    "                # get the publisher_name                    \n",
    "                # look for the PUBLISHER\n",
    "                if(object_type == 'publisher'):\n",
    "                \n",
    "                    publisher_name = json_data['citation']['publisher']\n",
    "                \n",
    "\n",
    "                # get the scopus_subject\n",
    "                # look for the SCOPUS\n",
    "                if(object_type == 'scopus_subjects'):\n",
    "\n",
    "\n",
    "            \n",
    "                    scopus_name = json_data['citation']['scopus_subjects'][0]\n",
    "\n",
    "            \n",
    "\n",
    "                # get the author\n",
    "                # look for the AUTHOR\n",
    "\n",
    "                # START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR\n",
    "                # START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR\n",
    "                # START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR\n",
    "                # START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR\n",
    "                # START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR\n",
    "                # START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR START AUTHOR\n",
    "            \n",
    "            \n",
    "                # look for the subject(s)\n",
    "                if(object_type == 'authors'):\n",
    "\n",
    "                    \n",
    "                    # re-initialize author_name\n",
    "                    author_name = ''\n",
    "\n",
    "                    # loop through the author array in json file and put every author into the json_array\n",
    "                    for author_index in json_data['citation']['authors']:\n",
    "\n",
    "\n",
    "                        # check for null, if its null (None) continue to the next file\n",
    "                        if(author_index == None):\n",
    "                            \n",
    "                            continue\n",
    "                        \n",
    "                        # check for an array (list), if its an array skip it\n",
    "                        if(author_index == []):\n",
    "                            \n",
    "                            continue\n",
    "                        \n",
    "                        # parse through the author here and normalize it\n",
    "                        name = author_index\n",
    "\n",
    "                        # tokenize the token array\n",
    "                        json_array.append(word_tokenize(name))   \n",
    "\n",
    "\n",
    "                    # loop through the token and take out token with a comma, and tokens that have 2 or less characters\n",
    "                    for i in json_array:\n",
    "\n",
    "\n",
    "                        # loop through the elements in token array\n",
    "                        for j in i:\n",
    "\n",
    "                            # check for commas\n",
    "                            if j == ',':\n",
    "\n",
    "                                # temp_array is an array of tokenized authors, there should ever by 1 author in it\n",
    "                                temp_array.append(i)\n",
    "                                \n",
    "                                \n",
    "                                # go through elements  in the temp array\n",
    "                                \n",
    "                                # temp_i is a token from the 1 author in the temp_array, so this will loop through multiple tokens\n",
    "                                for temp_i in temp_array:\n",
    "                                \n",
    "                                \n",
    "                                    # if there are 3 tokens\n",
    "                                    if(len(temp_i) == 3 ):\n",
    "\n",
    "                                        # hold the lastName\n",
    "                                        temp_name = temp_i[0]\n",
    "\n",
    "                                        # put the firstName in the first element\n",
    "                                        holder_array.append(temp_i[2])\n",
    "\n",
    "                                        \n",
    "                                        # put the lastName in the second element (overwriting the comma)\n",
    "                                        holder_array.append(temp_name)\n",
    "\n",
    "                                        token.append(holder_array)\n",
    "                                        \n",
    "                                        # clear the arrays for next author\n",
    "                                        holder_array = []\n",
    "                                        json_array = []\n",
    "                                        \n",
    "                                        authorFlag = 1\n",
    "                                        \n",
    "                                        # break out\n",
    "                                        break\n",
    "                                        \n",
    "         \n",
    "                                # once the author with proper alignment is saved, clear the temp_array\n",
    "                                temp_array = []\n",
    "\n",
    "\n",
    "                                break\n",
    "\n",
    "                            \n",
    "                            # if a string in the author name has a length of 2 or less we don't want it\n",
    "                            if len(j) <= 2:\n",
    "\n",
    "                                break\n",
    "\n",
    "\n",
    "                            #if the element in i is equal to the last element in the author name\n",
    "                            if(i.index(j) == len(i) - 1):\n",
    "                                   \n",
    "                                #keep the rest\n",
    "                                token.append(i)\n",
    "                            \n",
    "                                # clear the json_array\n",
    "                                json_array = []\n",
    "                                \n",
    "                                # assign subjectFlag the value of 0\n",
    "                                authorFlag = 1\n",
    "                                \n",
    "                                break\n",
    "                    \n",
    "                        if(authorFlag == 1):\n",
    "\n",
    "                            collected += 1\n",
    "\n",
    "                            # break out\n",
    "                            \n",
    "                            # reset the authorFlag first\n",
    "                            authorFlag = 0\n",
    "                            break\n",
    "                        \n",
    "                        \n",
    "                        #if the current token is the last in an author's name\n",
    "                        if(json_array.index(i) == len(json_array) - 1): \n",
    "\n",
    "                            not_collected += 1\n",
    "                         \n",
    "\n",
    "                    # before we close the source file we can concatenate here\n",
    "                    if(token != []):\n",
    "\n",
    "                        author_get_count += 1\n",
    "\n",
    "                        holder = ''\n",
    "\n",
    "                        # loop through the token array and concatenatate the words with a space\n",
    "                        for i in token:\n",
    "\n",
    "                            for j in i:\n",
    "\n",
    "                                new_name += j\n",
    "                                new_name += ' '\n",
    "\n",
    "                            author_name = new_name\n",
    "\n",
    "                            # clear the new_name to start over\n",
    "                            new_name = ''\n",
    "\n",
    "\n",
    "                        # clear out the token\n",
    "                        token = []\n",
    "\n",
    "\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            # END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR END AUTHOR\n",
    "            \n",
    "\n",
    "            # close the current source file\n",
    "            source_file.close()\n",
    "            \n",
    "            \n",
    "            # create a dictionary with 9 values, the key will be the altmetric_id\n",
    "            # the 9 values are the names, counts, and prestige_scores for the 3 attributes\n",
    "\n",
    "            # we want to check if the current articles attribute match journal, publisher, and scopus arrays here\n",
    "\n",
    "            # CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL\n",
    "            # CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL\n",
    "            # CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL CHECK JOURNAL\n",
    "            what_index = 0\n",
    "            while what_index < len(journal_array):\n",
    "                \n",
    "                # for the key in the author array at this index\n",
    "                for key in journal_array[what_index]:\n",
    "\n",
    "                    # check journal\n",
    "                    if( key == journal_name):\n",
    "                        \n",
    "                        journal_count = journal_array[what_index][key][0]\n",
    "                        journal_prestige = '%.2f' % journal_array[what_index][key][2]\n",
    "                    \n",
    "                what_index += 1\n",
    "            \n",
    "\n",
    "            \n",
    "            # CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER\n",
    "            # CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER\n",
    "            # CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER\n",
    "            # CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER CHECK PUBLISHER\n",
    "            \n",
    "            \n",
    "            what_index = 0\n",
    "            #array_count = len(author_array)\n",
    "            #print('array_count is: ', array_count)\n",
    "            while what_index < len(publisher_array):\n",
    "                # for the key in the author array at this index\n",
    "                #for key in author_array[this_index]:\n",
    "                for key in publisher_array[what_index]:\n",
    "                    \n",
    "                    if( key == publisher_name):\n",
    "                        # print out a single element\n",
    "                        #print(publisher_array[what_index][key][1])\n",
    "                        \n",
    "                        publisher_count = publisher_array[what_index][key][0]\n",
    "                        publisher_prestige = '%.2f' % publisher_array[what_index][key][2]\n",
    "                        \n",
    "\n",
    "                what_index += 1\n",
    "            \n",
    "            \n",
    "            # CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS\n",
    "            # CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS\n",
    "            # CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS CHECK SCOPUS\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            what_index = 0\n",
    "            #array_count = len(author_array)\n",
    "            #print('array_count is: ', array_count)\n",
    "            while what_index < len(scopus_array):\n",
    "                # for the key in the author array at this index\n",
    "                #for key in author_array[this_index]:\n",
    "                for key in scopus_array[what_index]:\n",
    "                    \n",
    "                    if( key == scopus_name):\n",
    "                    \n",
    "                        scopus_count = scopus_array[what_index][key][0]\n",
    "                        scopus_prestige = '%.2f' % scopus_array[what_index][key][2]\n",
    "                    \n",
    "                    \n",
    "                what_index += 1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            # CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR\n",
    "            # CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR\n",
    "            # CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR\n",
    "            # CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR CHECK AUTHOR\n",
    "            \n",
    "            \n",
    "\n",
    "            # count and prestige must be re-initialezed to 0 here\n",
    "            author_count = 0\n",
    "            author_prestige = 0\n",
    "            \n",
    "            what_index = 0\n",
    "\n",
    "            while what_index < len(author_array):\n",
    "\n",
    "                for key in author_array[what_index]:\n",
    "                    \n",
    "\n",
    "                    if( key == author_name):\n",
    "                    \n",
    "                        author_count = author_array[what_index][key][0]\n",
    "                        author_prestige = '%.2f' % author_array[what_index][key][2]\n",
    "                    \n",
    "                what_index += 1\n",
    "            \n",
    "            \n",
    "            # assign NaNs to attributes with no features\n",
    "            if(author_count == 0):\n",
    "                author_count = 'NaN'\n",
    "                author_prestige = 'NaN'\n",
    "                \n",
    "            if(journal_count == 0):\n",
    "                journal_count = 'NaN'\n",
    "                journal_prestige = 'NaN'\n",
    "                \n",
    "            if(publisher_count == 0):\n",
    "                publisher_count = 'NaN'\n",
    "                publisher_prestige = 'NaN'\n",
    "                \n",
    "            if(scopus_count == 0):\n",
    "                scopus_count = 'NaN'\n",
    "                scopus_prestige = 'NaN'\n",
    "                \n",
    "                               \n",
    "                \n",
    "            \n",
    "            # target class\n",
    "            # re-initialize\n",
    "            popular_class = ''\n",
    "            \n",
    "            if(altmetric_score >= 3):\n",
    "                popular_class = 'yes'\n",
    "            else:\n",
    "                popular_class = 'no'\n",
    "            \n",
    "            # change altmetric_score from int to string\n",
    "            altmetric_score = str(altmetric_score)\n",
    "            \n",
    "            \n",
    "            # Assign features to the id_array\n",
    "            \n",
    "            \n",
    "            a.setdefault( temp_alt, [altmetric_score, journal_name, journal_count, journal_prestige, publisher_name, publisher_count, publisher_prestige, scopus_name, scopus_count, scopus_prestige, author_name, author_count, author_prestige, popular_class])\n",
    "            \n",
    "            \n",
    "            \n",
    "            # id_array format\n",
    "            # 0=altmetric_score, 1= journal_name, 2=journal_count, 3=journal_prestige, 4=publisher_name, 5=publisher_count, 6=publisher_prestige, 7=scopus_name, 8=scopus_count, 9=scopus_prestige, 10=author_name, 11=author_count, 12=author_prestige\n",
    "            # add the dictionary to the next spot in the array\n",
    "            id_array.append(a)\n",
    "                        \n",
    "                        \n",
    "            # clear the temporary arrays, dictionaries, variables\n",
    "            a = {}\n",
    "            \n",
    "            \n",
    "            \n",
    "            # this is only for visually updating output\n",
    "            if( article_count % 10000 == 0):\n",
    "\n",
    "                print('article_count: ', article_count)\n",
    "                print('\\n')\n",
    "            \n",
    "            \n",
    "            \n",
    "            altmetric_score = 0\n",
    "\n",
    "            journal_count = 0\n",
    "            journal_prestige = 0\n",
    "            \n",
    "            \n",
    "            publisher_count = 0\n",
    "            publisher_prestige = 0\n",
    "            \n",
    "            \n",
    "            scopus_count = 0\n",
    "            scopus_prestige = 0\n",
    "            \n",
    "            \n",
    "            author_count = 0\n",
    "            author_prestige = 0\n",
    "            \n",
    "            popular_class = ''\n",
    "            \n",
    "\n",
    "print('article count is: ', article_count)\n",
    "print('done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Build .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# 10\n",
    "\n",
    "# Build .csv file\n",
    "\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "# variables\n",
    "altIdFlag = 0\n",
    "publisherFlag = 0\n",
    "publishDateFlag = 0\n",
    "journalFlag = 0\n",
    "\n",
    "article_count = 0\n",
    "\n",
    "# create an array to hold the values that you want from the feature array\n",
    "# the array will be a row in the csv file\n",
    "row_array = []\n",
    "\n",
    "# constants\n",
    "\n",
    "\n",
    "# create an output file    \n",
    "outputFile = open('C:\\\\Users\\\\Dave\\\\Desktop\\\\feature_set_04.csv', 'w')\n",
    "\n",
    "# create writing object\n",
    "outputWriter = csv.writer(outputFile, quoting=csv.QUOTE_MINIMAL, lineterminator = '\\n')\n",
    "\n",
    "\n",
    "# OUTPUT LABELS\n",
    "# CREATE LABEL ARRAY AND # WRITE LABELS TO CSV FILE\n",
    "label_array = [\"Altmetric ID\", \"Altmetric Score\",\"Journal Distribution\", \"Journal Prestige\", \"Publisher Distribution\", \"Publisher Prestige\", \"Scopus Distribution\", \"Scopus Prestige\", \"Author Productivity\", \"Author Prestige\", \"Popular\"]\n",
    "outputWriter.writerow(label_array)\n",
    "            \n",
    "\n",
    "what_index = 0\n",
    "while what_index < len(id_array):\n",
    "\n",
    "    for key in id_array[what_index]:\n",
    "        \n",
    "        article_count += 1\n",
    "            \n",
    "        # id_array format\n",
    "        # key=altmetic_id\n",
    "        # 0=altmetric_score, 1= journal_name, 2=journal_count, 3=journal_prestige, 4=publisher_name, 5=publisher_count, 6=publisher_prestige, 7=scopus_name, 8=scopus_count, 9=scopus_prestige, 10=author_name, 11=author_count, 12=author_prestige   \n",
    "        # keep\n",
    "        # 0   23  56  89  11,12,13\n",
    "            \n",
    "            \n",
    "        row_array.append(key)\n",
    "        row_array.append(id_array[what_index][key][0])    # altmetric_score\n",
    "        row_array.append(id_array[what_index][key][2])    # journal_count\n",
    "        row_array.append(id_array[what_index][key][3])    # journal_prestige\n",
    "        row_array.append(id_array[what_index][key][5])    # publisher_count\n",
    "        row_array.append(id_array[what_index][key][6])    # publisher_prestige\n",
    "        row_array.append(id_array[what_index][key][8])    # scopus_count\n",
    "        row_array.append(id_array[what_index][key][9])    # scopus_prestige\n",
    "        row_array.append(id_array[what_index][key][11])   # author_count\n",
    "        row_array.append(id_array[what_index][key][12])   # author_presitge\n",
    "        row_array.append(id_array[what_index][key][13])   # popular_class\n",
    "        \n",
    "\n",
    "        # when you are done assigning values to the row_array write the row_array to the csv file\n",
    "        # write to csv\n",
    "        outputWriter.writerow(row_array) \n",
    "        \n",
    "        \n",
    "        row_array = []\n",
    "        \n",
    "\n",
    "        # this is only for visually updating output\n",
    "        if( article_count % 10000 == 0):\n",
    "            print('article_count: ', article_count)\n",
    "\n",
    "\n",
    "    what_index += 1\n",
    "    \n",
    "print('done')\n",
    "\n",
    "        \n",
    "# close the csv file\n",
    "outputFile.close()\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
